from flask import Flask, request, jsonify
import numpy as np
import pickle
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences

# âœ… Create the Flask app
app = Flask(__name__)

# âœ… Load trained model
model = load_model("emotion_model.h5")

# âœ… Load tokenizer
with open("tokenizer.pkl", "rb") as f:
    tokenizer = pickle.load(f)

# âœ… Load label names (e.g., ['sadness', 'joy', ...])
with open("label_names.pkl", "rb") as f:
    label_names = pickle.load(f)

# âœ… Define maximum sequence length used during training
max_len = 50

# âœ… Define the prediction route
@app.route("/predict", methods=["POST"])
def predict():
    # ðŸ“¥ Get JSON data
    data = request.get_json()
    if not data or "text" not in data:
        return jsonify({"error": "Missing 'text' field"}), 400

    text = data["text"]

    # ðŸ§  Preprocess: Tokenize + pad the input
    sequence = tokenizer.texts_to_sequences([text])
    padded = pad_sequences(sequence, maxlen=max_len)

    # ðŸ”® Make prediction
    pred = model.predict(padded)[0]
    emotion = label_names[np.argmax(pred)]
    confidence = float(np.max(pred))

    # âœ… Return result as JSON
    return jsonify({
        "text": text,
        "emotion": emotion,
        "confidence": round(confidence, 2)
    })

# âœ… Run the app
# For Gunicorn: No need to run manually
# For local testing: this block will work
if __name__ == "__main__":
    print("âœ… Running Flask dev server...")
    app.run(host="0.0.0.0", port=5000)
